{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3e7e7b1-1526-4d9a-a848-89fa7fceb184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Combined Essential Code Execution ---\n",
      "\n",
      "--- Installing/Updating necessary libraries ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: diffusers 0.36.0.dev0\n",
      "Uninstalling diffusers-0.36.0.dev0:\n",
      "  Successfully uninstalled diffusers-0.36.0.dev0\n",
      "Found existing installation: transformers 4.57.3\n",
      "Uninstalling transformers-4.57.3:\n",
      "  Successfully uninstalled transformers-4.57.3\n",
      "Found existing installation: accelerate 1.12.0\n",
      "Uninstalling accelerate-1.12.0:\n",
      "  Successfully uninstalled accelerate-1.12.0\n",
      "Found existing installation: huggingface-hub 0.36.0\n",
      "Uninstalling huggingface-hub-0.36.0:\n",
      "  Successfully uninstalled huggingface-hub-0.36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers\n",
      "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-is0xzgio\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-is0xzgio\n",
      "  Resolved https://github.com/huggingface/diffusers to commit f9c1e612fb85dd971beeba77c3ddc0826e2146a4\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib_metadata in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (7.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (0.28.1)\n",
      "Collecting huggingface-hub<2.0,>=0.34.0 (from diffusers==0.36.0.dev0)\n",
      "  Using cached huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (1.26.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (0.7.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from diffusers==0.36.0.dev0) (9.4.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (3.6)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->diffusers==0.36.0.dev0) (0.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: shellingham in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: typer-slim in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (4.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib_metadata->diffusers==0.36.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.36.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.36.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio->httpx<1.0.0->diffusers==0.36.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer-slim->huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (8.1.7)\n",
      "Using cached huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.36.0.dev0-py3-none-any.whl size=4681931 sha256=9fa4a82f4fd17b855866db0d7dd5215b2a7acf247fe8558a1dfbf8e304dc5cfc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vagbjli2/wheels/90/fb/48/a310c271ab42899362ff272062ced42133e5c4c9d0ce77df68\n",
      "Successfully built diffusers\n",
      "Installing collected packages: huggingface-hub, diffusers\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.18.0 requires accelerate>=0.21.0, which is not installed.\n",
      "peft 0.18.0 requires transformers, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed diffusers-0.36.0.dev0 huggingface-hub-1.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.49.0)\n",
      "Requirement already satisfied: xformers in /opt/conda/lib/python3.11/site-packages (0.0.33.post2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.4)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Installing collected packages: huggingface-hub, transformers, accelerate\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 1.2.3\n",
      "    Uninstalling huggingface_hub-1.2.3:\n",
      "      Successfully uninstalled huggingface_hub-1.2.3\n",
      "Successfully installed accelerate-1.12.0 huggingface-hub-0.36.0 transformers-4.57.3\n",
      "--- Library installation complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.9.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2025.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.22.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Combined Essential Code Execution ---\")\n",
    "\n",
    "# --- Library Installations & Reinstall (from dLLyfuZXaqO4 & 660ef323) ---\n",
    "print(\"\\n--- Installing/Updating necessary libraries ---\")\n",
    "!pip install Pillow\n",
    "# Uninstall current versions to ensure clean install from source\n",
    "!pip uninstall -y diffusers transformers accelerate huggingface-hub\n",
    "# Install diffusers from source (main branch)\n",
    "!pip install git+https://github.com/huggingface/diffusers\n",
    "# Re-install other core libraries to ensure compatibility\n",
    "!pip install transformers accelerate bitsandbytes xformers\n",
    "print(\"--- Library installation complete ---\")\n",
    "\n",
    "# Make sure required packages are installed\n",
    "!pip install -q peft accelerate\n",
    "\n",
    "# peft for image preprocessing\n",
    "!pip install -U peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686f385a-4ca1-4a57-8887-f7ae7f0d157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading BLIP model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /opt/conda/lib/python3.11/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLIP model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- BLIP Model Loading (from YdbFWisqY6HD) ---\n",
    "print(\"\\n--- Loading BLIP model ---\")\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch # Imported here for general use\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "print(\"BLIP model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e45d634f-ec17-4470-82c5-90ad0d987eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Data Preparation and Organization ---\n",
      "Found 49 images in /home/jovyan:\n",
      " - Re-loaded A01929.jpg\n",
      " - Re-loaded A02008.jpg\n",
      " - Re-loaded A00360.jpg\n",
      " - Re-loaded A01694.jpg\n",
      " - Re-loaded A01148.jpg\n",
      " - Re-loaded A01365.jpg\n",
      " - Re-loaded A01950.jpg\n",
      " - Re-loaded A02074.jpg\n",
      " - Re-loaded A01285.jpg\n",
      " - Re-loaded A01759.jpg\n",
      " - Re-loaded A01680.jpg\n",
      " - Re-loaded A01072.jpg\n",
      " - Re-loaded A01349.jpg\n",
      " - Re-loaded A01990.jpg\n",
      " - Re-loaded A01824.jpg\n",
      " - Re-loaded A01237.jpg\n",
      " - Re-loaded A01996.jpg\n",
      " - Re-loaded A01796.jpg\n",
      " - Re-loaded A01889.jpg\n",
      " - Re-loaded A01815.jpg\n",
      " - Re-loaded A01615.jpg\n",
      " - Re-loaded A01860.jpg\n",
      " - Re-loaded A01958.jpg\n",
      " - Re-loaded A01422.jpg\n",
      " - Re-loaded A01181.jpg\n",
      " - Re-loaded A01676.jpg\n",
      " - Re-loaded A00367.jpg\n",
      " - Re-loaded A01909.jpg\n",
      " - Re-loaded A02077.jpg\n",
      " - Re-loaded A02079.jpg\n",
      " - Re-loaded A02049.jpg\n",
      " - Re-loaded A01467.jpg\n",
      " - Re-loaded A01531.jpg\n",
      " - Re-loaded A01736.jpg\n",
      " - Re-loaded A01806.jpg\n",
      " - Re-loaded A01411.jpg\n",
      " - Re-loaded A01906.jpg\n",
      " - Re-loaded A01939.jpg\n",
      " - Re-loaded A01681.jpg\n",
      " - Re-loaded A01834.jpg\n",
      " - Re-loaded A01457.jpg\n",
      " - Re-loaded A01054.jpg\n",
      " - Re-loaded A01077.jpg\n",
      " - Re-loaded A01729.jpg\n",
      " - Re-loaded A02005.jpg\n",
      " - Re-loaded A01258.jpg\n",
      " - Re-loaded A01356.jpg\n",
      " - Re-loaded A01157.jpg\n",
      " - Re-loaded A01399.jpg\n",
      "\n",
      "Successfully re-loaded 49 images.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting Data Preparation and Organization ---\")\n",
    "import os, shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Use current working directory (which is /home/jovyan in JupyterHub)\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Find images in your working directory\n",
    "image_paths = [f for f in os.listdir(base_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "loaded_images = []\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in {base_dir}:\")\n",
    "for img_name in image_paths:\n",
    "    img_path = os.path.join(base_dir, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        loaded_images.append((img_name, img))\n",
    "        print(f\" - Re-loaded {img_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\" - Could not re-load {img_name}: {e}\")\n",
    "print(f\"\\nSuccessfully re-loaded {len(loaded_images)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92002669-8904-400e-b09f-9997a9dd8925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Regenerated caption for 'A01929.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A02008.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A00360.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01694.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01148.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01365.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01950.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A02074.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01285.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01759.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01680.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01072.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01349.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01990.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01824.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01237.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01996.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01796.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01889.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01815.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01615.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01860.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01958.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01422.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01181.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01676.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A00367.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01909.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A02077.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A02079.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A02049.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01467.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01531.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01736.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01806.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01411.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01906.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01939.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01681.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01834.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01457.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01054.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01077.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01729.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A02005.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01258.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01356.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01157.jpg' (approx. 37 words).\n",
      " - Regenerated caption for 'A01399.jpg' (approx. 37 words).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "captioned_images_info = []\n",
    "mugshot_prompt = \"\"\"A detailed description of a person in a mugshot, focusing on their\n",
    "facial features, expression, hair,\n",
    "# Define the target dataset directory structure\n",
    "dataset_dir = \"lora_dataset\"\n",
    "instance_images_dir = os.path.join(dataset_dir, \"instance_images\")\n",
    "instance_captions_dir = os.path.join(dataset_dir, \"instance_captions\")\n",
    "mixed_images_dir = os.path.join(dataset_dir, \"images\") # Used for cleanup\n",
    "\n",
    "# Clean up existing mixed directory if it exists and create new structured ones\n",
    "if os.path.exists(mixed_images_dir):\n",
    "    print(f\"Removing existing mixed directory: {mixed_images_dir}\")\n",
    "    shutil.rmtree(mixed_images_dir)\n",
    "\n",
    "os.makedirs(instance_images_dir, exist_ok=True)\n",
    "os.makedirs(instance_captions_dir, exist_ok=True)\n",
    "print(f\"\\nCreated directory: {instance_images_dir}\")\n",
    "print(f\"Created directory: {instance_captions_dir}\")\n",
    "\n",
    "print(\"\\nOrganizing image and caption files:\")\n",
    "for item in captioned_images_info:\n",
    "    image_name = item[\"image_file\"]\n",
    "    caption_name = item[\"caption_file\"]\n",
    "\n",
    "    src_image_path = os.path.join(\"/content\", image_name)\n",
    "    src_caption_path = os.path.join(\"/content\", caption_name)\n",
    "\n",
    "    dest_image_path = os.path.join(instance_images_dir, image_name)\n",
    "    dest_caption_path = os.path.join(instance_captions_dir, caption_name)\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(src_image_path):\n",
    "            shutil.move(src_image_path, dest_image_path)\n",
    "            print(f\"Moved image '{image_name}' to '{instance_images_dir}'\")\n",
    "        if os.path.exists(src_caption_path):\n",
    "            shutil.move(src_caption_path, dest_caption_path)\n",
    "            print(f\"Moved caption '{caption_name}' to '{instance_captions_dir}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error moving files for {image_name}: {e}\")\n",
    "\n",
    "print(f\"\\nFinished organizing dataset. Images are in '{instance_images_dir}' and captions in '{instance_captions_dir}'.\")\n",
    "print(\"--- Data Preparation and Organization Complete ---\") and any distinguishing characteristics or clothing.\n",
    "The person is pictured from the chest up, with a neutral background, for identification purposes.\"\"\"\n",
    "\n",
    "for img_name, img_pil in loaded_images:\n",
    "    try:\n",
    "        inputs = processor(img_pil, mugshot_prompt, return_tensors=\"pt\")\n",
    "        out = model.generate(**inputs, max_new_tokens=100, num_beams=4, early_stopping=True)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        caption_filename = f\"{base_name}.txt\"\n",
    "        caption_filepath = os.path.join(base_dir, caption_filename)\n",
    "\n",
    "        with open(caption_filepath, \"w\") as f:\n",
    "            f.write(caption)\n",
    "\n",
    "        captioned_images_info.append({\n",
    "            \"image_file\": img_name,\n",
    "            \"caption_file\": caption_filename,\n",
    "            \"caption\": caption\n",
    "        })\n",
    "        print(f\" - Regenerated caption for '{img_name}' (approx. {len(caption.split())} words).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" - Could not regenerate caption for {img_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62980862-5b91-4b89-b263-e06a3ee2bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created directory: /home/jovyan/lora_dataset/instance_images\n",
      "Created directory: /home/jovyan/lora_dataset/instance_captions\n",
      "\n",
      "Organizing image and caption files:\n",
      "Moved image 'A01929.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01929.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A02008.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A02008.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A00360.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A00360.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01694.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01694.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01148.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01148.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01365.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01365.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01950.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01950.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A02074.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A02074.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01285.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01285.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01759.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01759.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01680.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01680.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01072.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01072.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01349.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01349.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01990.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01990.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01824.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01824.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01237.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01237.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01996.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01996.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01796.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01796.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01889.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01889.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01815.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01815.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01615.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01615.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01860.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01860.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01958.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01958.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01422.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01422.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01181.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01181.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01676.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01676.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A00367.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A00367.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01909.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01909.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A02077.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A02077.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A02079.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A02079.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A02049.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A02049.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01467.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01467.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01531.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01531.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01736.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01736.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01806.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01806.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01411.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01411.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01906.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01906.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01939.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01939.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01681.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01681.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01834.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01834.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01457.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01457.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01054.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01054.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01077.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01077.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01729.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01729.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A02005.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A02005.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01258.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01258.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01356.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01356.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01157.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01157.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "Moved image 'A01399.jpg' to '/home/jovyan/lora_dataset/instance_images'\n",
      "Moved caption 'A01399.txt' to '/home/jovyan/lora_dataset/instance_captions'\n",
      "\n",
      "Finished organizing dataset. Images are in '/home/jovyan/lora_dataset/instance_images' and captions in '/home/jovyan/lora_dataset/instance_captions'.\n",
      "--- Data Preparation and Organization Complete ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean up existing mixed directory if it exists and create new structured ones\n",
    "if os.path.exists(mixed_images_dir):\n",
    "    print(f\"Removing existing mixed directory: {mixed_images_dir}\")\n",
    "    shutil.rmtree(mixed_images_dir)\n",
    "\n",
    "os.makedirs(instance_images_dir, exist_ok=True)\n",
    "os.makedirs(instance_captions_dir, exist_ok=True)\n",
    "print(f\"\\nCreated directory: {instance_images_dir}\")\n",
    "print(f\"Created directory: {instance_captions_dir}\")\n",
    "\n",
    "print(\"\\nOrganizing image and caption files:\")\n",
    "for item in captioned_images_info:\n",
    "    image_name = item[\"image_file\"]\n",
    "    caption_name = item[\"caption_file\"]\n",
    "\n",
    "    src_image_path = os.path.join(base_dir, image_name)\n",
    "    src_caption_path = os.path.join(base_dir, caption_name)\n",
    "\n",
    "    dest_image_path = os.path.join(instance_images_dir, image_name)\n",
    "    dest_caption_path = os.path.join(instance_captions_dir, caption_name)\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(src_image_path):\n",
    "            shutil.move(src_image_path, dest_image_path)\n",
    "            print(f\"Moved image '{image_name}' to '{instance_images_dir}'\")\n",
    "        if os.path.exists(src_caption_path):\n",
    "            shutil.move(src_caption_path, dest_caption_path)\n",
    "            print(f\"Moved caption '{caption_name}' to '{instance_captions_dir}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error moving files for {image_name}: {e}\")\n",
    "\n",
    "print(f\"\\nFinished organizing dataset. Images are in '{instance_images_dir}' and captions in '{instance_captions_dir}'.\")\n",
    "print(\"--- Data Preparation and Organization Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4eb9c5-0725-4440-95a9-612eb4d94f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Training Stable diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab2861f-b0b6-4ccc-b38b-bd19dffd180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 17 15:28:34 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:C2:00.0 Off |                    0 |\n",
      "| N/A   40C    P0             72W /  300W |       0MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d834da-b50d-4c50-80fa-17e77a79634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Starting Combined Essential Code Execution ---\")\n",
    "\n",
    "# --- Library Installations & Reinstall (from dLLyfuZXaqO4 & 660ef323) ---\n",
    "print(\"\\n--- Installing/Updating necessary libraries ---\")\n",
    "!pip install Pillow\n",
    "# Uninstall current versions to ensure clean install from source\n",
    "!pip uninstall -y diffusers transformers accelerate huggingface-hub\n",
    "# Install diffusers from source (main branch)\n",
    "!pip install git+https://github.com/huggingface/diffusers\n",
    "# Re-install other core libraries to ensure compatibility\n",
    "!pip install transformers accelerate bitsandbytes xformers\n",
    "print(\"--- Library installation complete ---\")\n",
    "\n",
    "# Make sure required packages are installed\n",
    "!pip install -q peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce3c36-9991-42f9-b6ff-0b7af53d3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Download LoRA training script (from a36492ad) ---\n",
    "print(\"\\n--- Downloading LoRA training script ---\")\n",
    "script_url = \"https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_lora.py\"\n",
    "script_name = \"train_dreambooth_lora.py\"\n",
    "import os\n",
    "!wget -O {script_name} {script_url}\n",
    "if os.path.exists(script_name):\n",
    "    print(f\"Script '{script_name}' downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download '{script_name}'.\")\n",
    "print(\"--- Script download complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e438a80-af52-4758-8f8b-7b5de842b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Base Stable Diffusion model ID set: runwayml/stable-diffusion-v1-5 ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Stable Diffusion Base Model ID (from Dh5HyB63fHK4 for inference setup) ---\n",
    "# Note: The base model will be loaded again within the accelerate training script, and then re-loaded for inference after training with LoRA weights.\n",
    "from diffusers import StableDiffusionPipeline\n",
    "pretrained_model_name_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "print(f\"\\n--- Base Stable Diffusion model ID set: {pretrained_model_name_or_path} ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef0750e-8b58-46c2-afaa-2897a971c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Combined 49 images into /home/jovyan/lora_dataset/instance_data\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Paths\n",
    "images_dir   = \"/home/jovyan/lora_dataset/instance_images\"\n",
    "captions_dir = \"/home/jovyan/lora_dataset/instance_captions\"\n",
    "combined_dir = \"/home/jovyan/lora_dataset/instance_data\"\n",
    "\n",
    "# Create combined folder if it doesn't exist\n",
    "os.makedirs(combined_dir, exist_ok=True)\n",
    "\n",
    "# Copy images and their matching captions\n",
    "img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(img_exts)]\n",
    "\n",
    "missing_captions = []\n",
    "\n",
    "for img_file in image_files:\n",
    "    base = os.path.splitext(img_file)[0]\n",
    "    caption_file = base + \".txt\"\n",
    "\n",
    "    # Copy image\n",
    "    shutil.copy(os.path.join(images_dir, img_file), os.path.join(combined_dir, img_file))\n",
    "\n",
    "    # Copy caption if exists\n",
    "    if os.path.exists(os.path.join(captions_dir, caption_file)):\n",
    "        shutil.copy(os.path.join(captions_dir, caption_file), os.path.join(combined_dir, caption_file))\n",
    "    else:\n",
    "        missing_captions.append(img_file)\n",
    "\n",
    "print(f\" Combined {len(image_files)} images into {combined_dir}\")\n",
    "if missing_captions:\n",
    "    print(f\" Missing captions for {len(missing_captions)} images: {missing_captions[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44148c30-f013-45db-989c-532769e7d8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae872555-af24-42c2-b9a1-a425eb1f28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Optimized LoRA Training Parameters ---\n",
      "Pretrained Model: runwayml/stable-diffusion-v1-5\n",
      "Output Directory: /home/jovyan/lora_dreambooth_model\n",
      "Class Prompt: a photo of a person\n",
      "Resolution: 512\n",
      "Train Batch Size: 1\n",
      "Gradient Accumulation Steps: 2\n",
      "Learning Rate: 5e-05\n",
      "LR Scheduler: constant\n",
      "LR Warmup Steps: 0\n",
      "Number of Training Epochs: 30\n",
      "Seed: 42\n",
      "--- Optimized LoRA Training Parameters Defined ---\n"
     ]
    }
   ],
   "source": [
    "# --- Define Optimized LoRA Training Parameters ---\n",
    "print(\"\\n--- Defining Optimized LoRA Training Parameters ---\")\n",
    "\n",
    "script_name = \"train_dreambooth_lora.py\"\n",
    "output_dir = \"/home/jovyan/lora_dreambooth_model\"\n",
    "class_prompt = \"a photo of a person\"\n",
    "resolution = 512\n",
    "train_batch_size = 1\n",
    "gradient_accumulation_steps = 2   # reduced for faster training\n",
    "learning_rate = 5e-5              # lower for stability\n",
    "lr_scheduler = \"constant\"\n",
    "lr_warmup_steps = 0\n",
    "num_train_epochs = 30             # reduced to avoid overfitting\n",
    "seed = 42\n",
    "\n",
    "# for large dataset / actual training \n",
    "# train_batch_size = 2\n",
    "# gradient_accumulation_steps = 4\n",
    "# learning_rate = 2e-5\n",
    "# num_train_epochs = 5\n",
    "# resolution = 512\n",
    "# checkpointing_steps = 2000 # save model checkpoint after this many steps\n",
    "\n",
    "print(f\"Pretrained Model: {pretrained_model_name_or_path}\")\n",
    "print(f\"Output Directory: {output_dir}\")\n",
    "print(f\"Class Prompt: {class_prompt}\")\n",
    "print(f\"Resolution: {resolution}\")\n",
    "print(f\"Train Batch Size: {train_batch_size}\")\n",
    "print(f\"Gradient Accumulation Steps: {gradient_accumulation_steps}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"LR Scheduler: {lr_scheduler}\")\n",
    "print(f\"LR Warmup Steps: {lr_warmup_steps}\")\n",
    "print(f\"Number of Training Epochs: {num_train_epochs}\")\n",
    "print(f\"Seed: {seed}\")\n",
    "print(\"--- Optimized LoRA Training Parameters Defined ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e45918-875a-4df1-b53f-4645604ed483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do someting like this in the train script to save the model after some time\n",
    "# import time\n",
    "# last_save = time.time()\n",
    "# save_interval = 1800  # 30 minutes in seconds\n",
    "\n",
    "# for step, batch in enumerate(train_dataloader):\n",
    "    # training step...\n",
    "#    if time.time() - last_save > save_interval:\n",
    "#        accelerator.unwrap_model(unet).save_pretrained(output_dir)\n",
    "#        last_save = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860f7a3-cdee-455b-84d7-59eee23daace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Executing Optimized LoRA Training Command ---\n",
      "The optimized training command is:\n",
      "accelerate launch train_dreambooth_lora.py --pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 --instance_data_dir=/home/jovyan/lora_dataset/instance_images --output_dir=/home/jovyan/lora_dreambooth_model --instance_prompt=\"a photo of a zyz mugshot person\" --class_prompt=\"a photo of a person\" --resolution=512 --train_batch_size=1 --gradient_accumulation_steps=2 --learning_rate=5e-05 --lr_scheduler=constant --lr_warmup_steps=0 --num_train_epochs=30 --seed=42 --mixed_precision=fp16 --enable_xformers_memory_efficient_attention --checkpointing_steps=1000 --allow_tf32 \n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /opt/conda/lib/python3.11/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/jovyan/train_dreambooth_lora.py:560: UserWarning: You need not use --class_prompt without --with_prior_preservation.\n",
      "  warnings.warn(\"You need not use --class_prompt without --with_prior_preservation.\")\n",
      "/opt/conda/lib/python3.11/site-packages/accelerate/accelerator.py:529: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "12/17/2025 16:30:41 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'rescale_betas_zero_snr', 'prediction_type', 'variance_type', 'sample_max_value', 'clip_sample_range', 'timestep_spacing', 'thresholding', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
      "{'force_upcast', 'use_post_quant_conv', 'latents_std', 'scaling_factor', 'shift_factor', 'latents_mean', 'use_quant_conv', 'mid_block_add_attention'} was not found in config. Values will be initialized to default values.\n",
      "All model checkpoint weights were used when initializing AutoencoderKL.\n",
      "\n",
      "All the weights of AutoencoderKL were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
      "{'projection_class_embeddings_input_dim', 'class_embeddings_concat', 'addition_embed_type', 'encoder_hid_dim_type', 'conv_out_kernel', 'mid_block_only_cross_attention', 'mid_block_type', 'num_class_embeds', 'time_embedding_type', 'time_embedding_dim', 'reverse_transformer_layers_per_block', 'resnet_time_scale_shift', 'only_cross_attention', 'class_embed_type', 'resnet_out_scale_factor', 'conv_in_kernel', 'timestep_post_act', 'addition_time_embed_dim', 'dual_cross_attention', 'attention_type', 'cross_attention_norm', 'transformer_layers_per_block', 'time_cond_proj_dim', 'use_linear_projection', 'num_attention_heads', 'upcast_attention', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'dropout', 'time_embedding_act_fn', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.\n",
      "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
      "\n",
      "All the weights of UNet2DConditionModel were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
      "12/17/2025 16:31:01 - INFO - __main__ - ***** Running training *****\n",
      "12/17/2025 16:31:01 - INFO - __main__ -   Num examples = 49\n",
      "12/17/2025 16:31:01 - INFO - __main__ -   Num batches each epoch = 49\n",
      "12/17/2025 16:31:01 - INFO - __main__ -   Num Epochs = 30\n",
      "12/17/2025 16:31:01 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "12/17/2025 16:31:01 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "12/17/2025 16:31:01 - INFO - __main__ -   Gradient Accumulation steps = 2\n",
      "12/17/2025 16:31:01 - INFO - __main__ -   Total optimization steps = 750\n",
      "Steps:  36%|       | 273/750 [02:02<03:36,  2.20it/s, loss=0.0915, lr=5e-5]"
     ]
    }
   ],
   "source": [
    "# --- Execute Optimized LoRA Model Training ---\n",
    "print(\"\\n--- Executing Optimized LoRA Training Command ---\")\n",
    "\n",
    "accelerate_command = (\n",
    "    f\"accelerate launch {script_name} \"\n",
    "    f\"--pretrained_model_name_or_path={pretrained_model_name_or_path} \"\n",
    "    f\"--instance_data_dir=/home/jovyan/lora_dataset/instance_images \"\n",
    "    f\"--output_dir={output_dir} \"\n",
    "    f\"--instance_prompt=\\\"{instance_prompt}\\\" \"\n",
    "    f\"--class_prompt=\\\"{class_prompt}\\\" \"\n",
    "    f\"--resolution={resolution} \"\n",
    "    f\"--train_batch_size={train_batch_size} \"\n",
    "    f\"--gradient_accumulation_steps={gradient_accumulation_steps} \"\n",
    "    f\"--learning_rate={learning_rate} \"\n",
    "    f\"--lr_scheduler={lr_scheduler} \"\n",
    "    f\"--lr_warmup_steps={lr_warmup_steps} \"\n",
    "    f\"--num_train_epochs={num_train_epochs} \"\n",
    "    f\"--seed={seed} \"\n",
    "    f\"--mixed_precision=fp16 \"\n",
    "    f\"--enable_xformers_memory_efficient_attention \"\n",
    "    f\"--checkpointing_steps=1000 \"\n",
    "    f\"--allow_tf32 \"\n",
    ")\n",
    "\n",
    "print(f\"The optimized training command is:\\n{accelerate_command}\")\n",
    "!{accelerate_command}\n",
    "print(\"--- Optimized LoRA training command executed. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40143320-2882-4b7b-b2ef-2607a70a4c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.9.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2025.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.22.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1044b26-9744-452f-93fd-4472cd3c4b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting LoRA Inference ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|| 7/7 [00:00<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Stable Diffusion pipeline ready for inference with CPU offload.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No LoRA keys associated to CLIPTextModel found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModel related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LoRA weights loaded from '/home/jovyan/lora_dreambooth_model/pytorch_lora_weights.safetensors'\n",
      "\n",
      "Generating images...\n",
      "Generating image for prompt: 'a photo of a zyz mugshot person, professional studio lighting, high detail, sharp focus'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [00:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to: generated_images/generated_image_1.png\n",
      "Generating image for prompt: 'a candid shot of a zyz mugshot person smiling, outdoor lighting, natural look'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [00:01<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to: generated_images/generated_image_2.png\n",
      "Generating image for prompt: 'a painting of a zyz mugshot person, impressionist style, vibrant colors'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [00:01<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to: generated_images/generated_image_3.png\n",
      "Generating image for prompt: 'a black and white photo of a zyz mugshot person, serious expression, dramatic shadows'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [00:01<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to: generated_images/generated_image_4.png\n",
      "Generating image for prompt: 'a digital art of a zyz mugshot person, futuristic cyberpunk setting, neon lights'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [00:01<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to: generated_images/generated_image_5.png\n",
      "--- LoRA Inference Complete ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting LoRA Inference ---\")\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch, os\n",
    "\n",
    "# Load base SD pipeline with CPU offload\n",
    "pretrained_model_name_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\"\n",
    ")\n",
    "pipeline.enable_model_cpu_offload()\n",
    "\n",
    "# Enable xformers if available\n",
    "try:\n",
    "    pipeline.enable_xformers_memory_efficient_attention()\n",
    "except Exception as e:\n",
    "    print(\"xformers not enabled:\", e)\n",
    "\n",
    "print(\"Base Stable Diffusion pipeline ready for inference with CPU offload.\")\n",
    "\n",
    "# Load LoRA weights\n",
    "lora_path = os.path.join(output_dir, \"pytorch_lora_weights.safetensors\")\n",
    "if os.path.exists(lora_path):\n",
    "    pipeline.load_lora_weights(lora_path)\n",
    "    print(f\" LoRA weights loaded from '{lora_path}'\")\n",
    "else:\n",
    "    print(f\" LoRA weights not found at '{lora_path}'\")\n",
    "\n",
    "# Prompts\n",
    "prompts = [\n",
    "    \"a photo of a zyz mugshot person, professional studio lighting, high detail, sharp focus\",\n",
    "    \"a candid shot of a zyz mugshot person smiling, outdoor lighting, natural look\",\n",
    "    \"a painting of a zyz mugshot person, impressionist style, vibrant colors\",\n",
    "    \"a black and white photo of a zyz mugshot person, serious expression, dramatic shadows\",\n",
    "    \"a digital art of a zyz mugshot person, futuristic cyberpunk setting, neon lights\"\n",
    "]\n",
    "\n",
    "output_image_dir = \"generated_images\"\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nGenerating images...\")\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"Generating image for prompt: '{prompt}'\")\n",
    "    image = pipeline(prompt, num_inference_steps=15, guidance_scale=7).images[0]\n",
    "    image_filename = os.path.join(output_image_dir, f\"generated_image_{i+1}.png\")\n",
    "    image.save(image_filename)\n",
    "    print(f\"Saved image to: {image_filename}\")\n",
    "\n",
    "print(\"--- LoRA Inference Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7cafe1-5fe6-4905-8bf4-5056dd7db089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 17 16:11:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:C2:00.0 Off |                    0 |\n",
      "| N/A   41C    P0             73W /  300W |    1038MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecdb9c-0a8a-49b0-906b-4f33658d6236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
