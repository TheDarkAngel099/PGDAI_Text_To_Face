{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844733bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# Load base model\n",
    "base_model = \"SG161222/RealVisXL_V4.0\"\n",
    "lora_model = \"/home/dai01/Text_To_Face/sd_training/outputs\"\n",
    "\n",
    "# Load pipeline\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "# Load LoRA weights\n",
    "pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_model)\n",
    "\n",
    "# Move to GPU\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Generate image\n",
    "prompt = \"mugshot, frontal view, centered, neutral expression, plain background\"\n",
    "image = pipe(prompt, num_inference_steps=50).images[0]\n",
    "image.save(\"generated_mugshot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33272f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"SG161222/RealVisXL_V4.0\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load LoRA directly\n",
    "pipe.load_lora_weights(\"/home/dai01/Text_To_Face/sd_training/outputs\")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(\"mugshot portrait\").images[0]\n",
    "image.save(\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48462b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"SG161222/RealVisXL_V4.0\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load LoRA directly\n",
    "pipe.load_lora_weights(\"/home/dai01/Text_To_Face/sd_training/outputs\")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(\"mugshot portrait\").images[0]\n",
    "image.save(\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e652630",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"mugshot, frontal view, neutral\",\n",
    "    \"mugshot, side profile, serious\",\n",
    "    \"mugshot photo, centered face\"\n",
    "]\n",
    "\n",
    "images = pipe(prompts, num_inference_steps=50).images\n",
    "for i, img in enumerate(images):\n",
    "    img.save(f\"mugshot_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality vs speed\n",
    "num_inference_steps=50     # 30-50 steps (higher=better but slower)\n",
    "guidance_scale=7.5         # Prompt strength (7-10 recommended)\n",
    "height=512, width=512      # Resolution (match training res)\n",
    "negative_prompt=\"blurry\"   # What to avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994830e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat > /home/dai01/Text_To_Face/sd_training/generate.py << 'EOF'\n",
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"SG161222/RealVisXL_V4.0\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.load_lora_weights(\"./outputs\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(\"mugshot, frontal view, centered, neutral expression\").images[0]\n",
    "image.save(\"generated.png\")\n",
    "print(\"Image saved as generated.png\")\n",
    "EOF"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
